<?xml version="1.0" encoding="UTF-8" ?>
<chapter xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="chap_laplace">
<!-- Copyright 2018-2020 Joel Feldman, Andrew Rechnitzer and Elyse Yeager -->
<!-- This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License-->
<!-- https://creativecommons.org/licenses/by-nc-sa/4.0 -->
<title>Laplace transforms</title>
<introduction>
  <p>
    In this chapter we study Laplace transforms, which give us a method for finding <em>analytic</em><fn>An analytic solution to an ODE is an exact solution typically expressed as some combination of standard functions, as opposed to a <em>numerical solution</em>, which is one developed in an incremental way from some kind of initial or boundary conditions, like you have been studying in the Numerical Methods unit.</fn> solutions to certain linear ordinary differential equations. A key concept for understanding the topics in this chapter is how the Laplace transform takes the original problem, the ODE, and <em>transforms</em> it into a related problem in a different setting that is easier to solve than the original one. The solution to this related problem is then <em>transformed back</em>, using the inverse Laplace transform, to recover the solution to the original ODE.
  </p>
  <p>
    This chapter on Laplace transforms was added here by Killian O'Brien in November 2022.
  </p>
</introduction>
<section xml:id="sec-terminology">
  <title>Terminology</title>
  <definition xml:id="def-de">
  <title>Differential equations</title>
    <statement>
      <p>
          A <em>differential equation</em> is an equation featuring one or more unknown functions and some of their derivatives. If the derivatives are all one-variable standard derivatives, e.g. <m>\frac{dy}{dt}</m> etc, then the equation is called an <em> ordinary differential equation</em> (ODE). If the derivatives are partial, e.g. <m>\frac{\partial y}{\partial t}</m> then the equation is called a <em>partial differential equation</em> (PDE).
      </p>
    </statement>
  </definition>


<p>Differential equations arise in a wide range of applications of mathematics to problems in motion, astronomy, physics, engineering, chemistry, biology , etc. In practice the differential equations one meets are often impossible to solve exactly (i.e. find an <em>analytic solution</em>) and instead we must use techniques to find approximations to the actual solutions (so called <em>numerical solutions</em>). However for special cases of ODEs we can describe methods to obtain exact solutions, one of which we describe in this chapter.</p>

<definition xml:id="def-linearODE">
<title>Linear and non-linear ODEs</title>
  <statement>
      <p>The method described here, Laplace transforms, can often find the exact solution to a <em>linear ordinary differential equation with constant coefficients</em>, i.e. one of the form
<me>
a_n \frac{d^ny}{dt^n} + \dots + a_1 \frac{dy}{dt} + a_0y = g(t),
</me>
where <m>y</m> is the unknown function whose solution is sought. Note that we are allowed a non-constant function <m>g</m> on the right hand side.</p>

<p>A <em>non-linear</em> ODE is one where some of the derivatives of <m>y</m>, or <m>y</m> itself, appear to a power higher than 1 or are multiplied together, such as in
<me>
t^4 \frac{d^2y}{dt^2} + y \frac{dy}{dt} = 0.
</me>
</p>
  </statement>
</definition>

<p>
  Solutions to ODEs will often feature a number of undetermined constants which can be determined if extra information is given in form of <em>boundary conditions</em>, i.e. known values of the solution <m>y</m> at certain points in the domain, or <em>initial conditions</em>, i.e. known values of the solution <m>y(t)</m>  and some of its derivatives at <m>t=0</m>. Such initial values usually come from knowing the initial state of a system, the future behaviour of which will be governed by the ODE.
</p>

<example>
  <statement>
    <p>
      Show how the boundary conditions <m>y(0)=1</m> and <m>y(1)=2</m> determine the constants that arise in the solution of
<me>
\frac{d^2y}{dt^2} = 0.
</me>
    </p>
  </statement>
  <solution>
    <p>
      See lecture.
    </p>
  </solution>
</example>
</section>


<section xml:id="sec-laplace_transform">
  <title>The transform and its properties</title>
<p>
In general a <em>transform</em> of a function, <m>x(t)</m> say, is a rule for associating a new function, <m>X(s)</m> say, to <m>x</m>. The new function depends on a new argument / variable <m>s</m>. The values of the original function <m>x(t)</m> are used somehow to define the new function <m>X</m>.
</p>

<definition xml:id="def-laplace-transform">
<title>Laplace transform</title>
  <statement>
    <p>
      Let <m>f</m> be a function defined on the positive real numbers. The <em>Laplace transform</em> of a function <m>f</m> is a function of a new variable <m>s</m> and is defined by the integral
<me>
\trans{f(t)} .
</me>
Various notations are commonly used for the Laplace transform of <m>f</m>. It can be denoted by any of
<me>
\L{f(t)}, \, \, \bar{f}(s) \text{ or } F(s).
</me>
    </p>
  </statement>
</definition>
<p>
The Laplace transform, <m>F(s)</m> makes sense as a complex valued function of the complex variable <m>s</m>. However we shall only consider it mostly as a function of the real variable <m>s</m>. In fact we shall not be making any particular use of the individual values of <m>F</m>, rather we shall be exploiting the existence of these transforms and their associated properties in order to find solutions to certain ODEs.
</p>
<p>
Of course a function only has a transform if the integral in definition <xref ref="def-laplace-transform"/> converges. This will be so for most of the functions that we meet. In general it is so for functions of <em>exponential type</em>, i.e. functions that eventually are dominated by a suitable exponential function <m>e^{\lambda t}</m>.
</p>

<p>
We can think of the Laplace transform of some kind of continuous analogue of a power series associated to a sequence of coefficients. This viewpoint is excellently described in a <url href="http://ocw.mit.edu/courses/mathematics/18-03-differential-equations-spring-2010/video-lectures/lecture-19-introduction-to-the-laplace-transform">video lecture</url> by Prof. Arthur Mattuck in the MIT OpenCourseWare Differential Equations course.
</p>

<example>
<title>The tranform of the constant function <m>1</m>.</title>
  <statement>
    <p>
      The Laplace transform, <m>\L{1}</m>, of the constant function <m>1</m> is given by 
      <me>
        \L{1} = \frac{1}{s}.
      </me>
    </p>
  </statement>
  <solution>
    <p>
<md>
  <mrow>\L{f(t)} \amp= \trans{1},</mrow>
  <mrow> \amp = \trans{},</mrow>
  <mrow> \amp = \left [ \frac{e^{-st}}{-s} \right ]_0^\infty, </mrow>
  <mrow> \amp = \frac{1}{s}, \text{ for $s>0$}.</mrow>
</md>
    </p>
  </solution>
</example>

<example>
  <title>The transform of the identity function, <m>f(t)=t</m>.</title>
  <statement>
    <p>
      If <m>f</m> is the function defined by <m>f(t) = t</m> for <m>t\geq 0</m> then <m>\L{f(t)}=\frac{1}{s^2}.</m>
    </p>
  </statement>
  <solution>
    <p>
      <md>
        <mrow>\L{f(t)} \amp = \trans{t},</mrow>
        <mrow> \amp = \int_0^\infty t \, \frac{d}{dt} \left ( \frac{e^{-st}}{-s} \right ) \, dt,</mrow>
        <mrow> \amp = \left [ t\,  \frac{e^{-st}}{-s} \right ]_0^\infty - \int_0^\infty \frac{e^{-st}}{-s} \, dt , \text{ int. by parts},</mrow>
        <mrow> \amp = \frac{1}{s} \int_0^\infty e^{-st} \, dt, \text{ for $s>0$},</mrow>
        <mrow> \amp =  \frac{1}{s^2}.</mrow>
      </md>
    </p>
  </solution>
</example>

<example>
  <title>Transform of the exponential</title>
  <statement>
    <p>
      If <m>f</m> is a function of exponential type like <m>f(t) = e^{-at}</m> for <m>t>0</m> and <m>a \in \mathbb{R}</m> then <m>\L{f(t)}=\frac{1}{s-a}</m>
    </p>
  </statement>
  <solution>
    <p>
      <md>
        <mrow>\L{f(t)} \amp = \trans{e^{-at}},</mrow>
        <mrow> \amp = \int_0^\infty e^{-(s+a)t} \, dt,</mrow>
        <mrow> \amp = \frac{1}{s+a}, \text{ for $s+a > 0$}.</mrow>
      </md>
    </p>
  </solution>
</example>
</section>

<section xml:id="sec-laplace_table">
  <title>Table of Laplace transforms</title>
  <p>
    Continuing in this vein we might find the Laplace transforms of all the standard functions that commonly arise in mathematics. However to make things easier, when we need to obtain transforms in practice we shall make use of a table of Laplace transforms, unless told otherwise. In table <xref ref="tab-laplace"/> you can find the transforms of the common functions we will encounter and a summary of some relevant properties of the transform.
  </p>

  <table xml:id="tab-laplace">
  <title>Transforms of common functions</title>
  <tabular top="major">
    <row bottom="minor">
      <cell>
        Function
      </cell>
      <cell>
        Transform <m>L[f(t)] = \displaystyle\int_0^\infty e^{-st}f(t) \, dt = \bar{f}(s)</m>
      </cell>
    </row>
    <row>
      <cell>
        1
      </cell>
      <cell>
        <m>\dfrac{1}{s}</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>t</m>
      </cell>
      <cell>
        <m>\dfrac{1}{s^2}</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>t^n</m>
      </cell>
      <cell>
        <m>\dfrac{n!}{s^{n+1}} \qquad n</m> is a positive integer
      </cell>
    </row>
    <row>
      <cell>
        <m>e^{-at}</m>
      </cell>
      <cell>
        <m>\dfrac{1}{s+a}</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>te^{-at}</m>
      </cell>
      <cell>
        <m>\dfrac{1}{(s+a)^2}</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>t^ne^{-at}</m>
      </cell>
      <cell>
        <m>\dfrac{n!}{(s+a)^{n+1}}\qquad n</m> is a positive integer
      </cell>
    </row>
    <row>
      <cell>
        <m>\sin(\omega t)</m>
      </cell>
      <cell>
        <m>\dfrac{\omega}{s^2 + \omega^2}</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>\cos(\omega t)</m>
      </cell>
      <cell>
        <m>\dfrac{s}{s^2 + \omega^2}</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>t\sin(\omega t)</m>
      </cell>
      <cell>
        <m>\dfrac{2\omega s}{(s^2 + \omega^2)^2}</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>t\cos(\omega t)</m>
      </cell>
      <cell>
        <m>\dfrac{s^2 - \omega^2}{(s^2 + \omega^2)^2}</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>\sinh(\omega t)</m>
      </cell>
      <cell>
        <m>\dfrac{\omega}{s^2 - \omega^2}</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>\cosh(\omega t)</m>
      </cell>
      <cell>
        <m>\dfrac{s}{s^2 - \omega^2}</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>e^{-at}\sin(\omega t)</m>
      </cell>
      <cell>
        <m>\dfrac{\omega}{(s+a)^2+\omega^2}</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>e^{-at}\cos(\omega t)</m>
      </cell>
      <cell>
        <m>\dfrac{s+a}{(s+a)^2+\omega^2}</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>e^{-at}\sinh(\omega t)</m>
      </cell>
      <cell>
        <m>\dfrac{\omega}{(s+a)^2-\omega^2}</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>e^{-at}\cosh(\omega t)</m>
      </cell>
      <cell>
        <m>\dfrac{s+a}{(s+a)^2-\omega^2}</m>
      </cell>
    </row>
    <row>
      <cell>
        Unit step function <m>H(t)</m>
      </cell>
      <cell>
        <m>\dfrac{1}{s}</m>
      </cell>
    </row>
    <row>
      <cell>
        Unit impulse function <m>\delta (t)</m>
      </cell>
      <cell>
        1
      </cell>
    </row>
    <row>
      <cell>
        <m>H(t-a)</m>
      </cell>
      <cell>
        <m>\dfrac{1}{s}e^{-as}</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>\delta (t-a)</m>
      </cell>
      <cell>
        <m>e^{-as}</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>e^{-at}f(t)</m>
      </cell>
      <cell>
        <m>\bar{f}(s+a)</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>tf(t)</m>
      </cell>
      <cell>
        <m>-\dfrac{d}{ds} \bar{f}(s)</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>f(t-a)H(t-a)</m>
      </cell>
      <cell>
        <m>e^{-as}\bar{f}(s)</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>\dfrac{dx}{dt}</m>
      </cell>
      <cell>
        <m>s\bar{x}-x_0</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>\dfrac{d^2x}{dt^2}</m>
      </cell>
      <cell>
        <m>s^2\bar{x}-sx_0-x_1</m>
      </cell>
    </row>
    <row>
      <cell>
        <m>\dfrac{d^3x}{dt^3}</m>
      </cell>
      <cell>
        <m>s^3\bar{x}-s^2x_0-sx_1-x_2</m>
      </cell>
    </row>
    <row bottom="major">
      <cell>
        <m>\displaystyle \int_0^t f(t) \, dt</m>
      </cell>
      <cell>
        <m>\dfrac{1}{s}\bar{f}(s)</m>
      </cell>
    </row>
  </tabular>
</table>
</section>

<section xml:id="sec-transform_properties">
  <title>Properties of the transform</title>
  <p>
    We now discuss some important properties of the transform that follow from the definition <xref ref="def-laplace-transform"/> and examples of using them to find transforms of futher functions.
  </p>
  <theorem xml:id="thm-transform_linearity">
  <title>Linearity of the transform</title>
      <statement>
      <p>
        The Laplace transform is linear, i.e. if <m>f</m> and <m>g</m> are two functions with Laplace transforms then for all <m>\alpha, \beta \in \mathbb{R}</m>,
        <me>
          \L{\alpha f + \beta g} = \alpha\L{f} + \beta \L{g}.
        </me>
             </p>
    </statement>
    <proof>
      <p>
        This follows directly from the linearity of integration.
      </p>
    </proof>
  </theorem>
  <example>
  <title>Appying linearity</title>
      <statement>
      <p>
        Find the Laplace transform <m>\L{3t + 4e^{-2t}}</m>.
      </p>
    </statement>
    <solution>
      <p>
        <md>
          <mrow>\L{3t + 4e^{-2t}} \amp = 3 \L{t} + 4 \L{e^{-2t}} , </mrow>
          <mrow> \amp = \frac{3}{s^2} + \frac{4}{s+2}. </mrow>
        </md>
      </p>
    </solution>
  </example>
  <p>
    The next result links the derivative of a transform to the process of multiplying the original function by <m>t</m>.
  </p>
  <theorem xml:id="thm-deriv_of_transform">
  <title>Derivative of the transform</title>
      <statement>
      <p>
        Let <m>f</m> be a function with transform <m>F(s) = \L{f(t)}</m>, then 
        <me>
          \L{tf(t)} = - \frac{dF}{ds}.
        </me>
      </p>
    </statement>
    <proof>
      <p>
        <md>
          <mrow>-\frac{dF}{ds} \amp = - \frac{d}{ds} \left ( \trans{f(t)} \right )  , </mrow>
          <mrow> \amp  =  - \int_0^\infty \frac{\partial}{\partial s} \left ( e^{-st} f(t) \right ) \, dt ,</mrow>
          <mrow> \amp  = - \int_0^\infty -t e^{-st} f(t) \, dt </mrow>
          <mrow> \amp  = \trans{t f(t)}, </mrow>
          <mrow> \amp  = \L{tf(t)}.</mrow>
        </md>
      </p>
    </proof>
  </theorem>
  <p>
    In a previous example we found that <m>\L{t}=\frac{1}{s}</m>. Now we can apply theorem <xref ref="thm-deriv_of_transform"/> to find <m>\L{t^n}</m> for any positive integer <m>n</m>.
  </p>
  
  <example xml:id="eg-trans_poly_term">
  <title>Transforms of polynomial terms</title>
      <statement>
      <p>
      For any integer <m>n\geq 0</m>,
      <me>
        \L{t^n} = \frac{n!}{s^{n+1}}
      </me></p>
    </statement>
    <solution>
      <p>
        The base case of <m>\L{t^0}=\L{1}=1/s</m> has already been proven. If <m>\L{t^k} = k!/s^{k+1}</m> then 
        <md>
          <mrow>\L{t^{k+1}} \amp = \L{t \cdot t^k},</mrow>
          <mrow> \amp = -\frac{d}{ds} \left ( \frac{k!}{s^{k+1}} \right ),</mrow>
          <mrow> \amp = - \left (-(k+1) \frac{k!}{s^{k+2}}  \right )  </mrow>
          <mrow> \amp = \frac{(k+1)!}{s^{k+2}}.</mrow>
        </md>
      and so the result follows by induction on <m>n</m>.
      </p>
    </solution>
  </example>
  <p>
    So now using linearity and example <xref ref="eg-trans_poly_term"/> we can find the transform of any poynomial in <m>t</m>.
  </p>

<p>
  The next property concerns taking the Laplace transform of the derivative of a function. This is a key property that enables the transform to be used as a tool to solve ODEs, as ODEs feature many derivatives of the unknown function that we wish to find.
</p>

<theorem xml:id="thm-trans_deriv">
<title>Transform of a derivative</title>  
  <statement>
    <p>
      Let <m>x</m> be a function having a Laplace transform <m>\L{x(t)}</m>. Then
<me>
\L{\frac{dx}{dt}} = s \L{x(t)} - x(0).
</me>
    </p>
  </statement>
  <proof>
    <p>
      This can be shown using integration by parts, as follows,
      <md>
        <mrow> \L{\frac{dx}{dt}} \amp =\trans{\frac{dx}{dt}} , </mrow>
        <mrow> \amp  =  \left [ e^{-st} x(t) \right ]_0^\infty - \int_0^\infty -se^{-st} x(t) \, dt </mrow>
        <mrow> \amp  = -x(0) + s \trans{x(t)} ,</mrow>
        <mrow> \amp = s \L{x(t)} - x(0),</mrow>
      </md>
      as required.
    </p>
  </proof>
</theorem>
<p>
  The transforms of higher order derivatives can be obtained by iterating this result.
</p>
<corollary xml:id="cor-trans-deriv">
  <statement>
    <p>
      Let <m>x</m> be a function having a Laplace transform <m>\L{x(t)}</m> and let <m>n \geq 1</m>. Then
      <me>
        \L{\frac{d^n x}{dt^n}} = s^n \L{x(t)} - \sum_{i=0}^{n-1} s^{n-1 - i}x_i,
      </me>
      where <m>x_i</m> denotes the initial value of the <m>i</m>th derivative of <m>x</m>, i.e.
      <me>
        x_i = \left. \frac{d^ix}{dt^i} \right |_{t=0}.
      </me>
      
    </p>
  </statement>
  <proof>
    <p>
      Use induction on <m>n</m>, base case provided by theorem <xref ref="thm-trans_deriv"/>.
    </p>
  </proof>
</corollary>
<p>
  Laplace transforms are invertible for most applications, and we will assume that this is the case. So we speak of the <em>inverse Laplace transform</em> of a function <m>F(s)</m> as being the function <m>f(t)</m> whose Laplace transform is <m>F(s)</m>, and we write
<me>
\Linv{F(s)} = f(t).
</me>
So for example <m>\Linv{\frac{1}{s^2}} = t</m> and <m>\Linv{\frac{1}{s-4}} = e^{4t}</m>.
</p>
<p>
The inverse transform of an arbitrary function <m>F(s)</m> can be expressed/evaluated as a certain integral in the complex plane of the product of suitable exponential and <m>F</m>. However for our purposes we think of finding an inverse transform as an exercise in using the Laplace transform table in reverse, although in many cases it will be necessary to use the method of partial fractions as a precursor to this.
</p>
</section>
<section xml:id="sec-ODE_solving">
  <title>Solving ODEs using the transform</title>
  <p>
    We describe here a four-step method for solving a linear ODE of the form
<me>
a_n \frac{d^ny}{dt^n} + \dots + a_1 \frac{dy}{dt} + a_0y = g(t),
</me>
by finding a suitable expression defining the unknown function <m>y(t)</m>. The method should work as long as the function <m>g</m> has a reasonable Laplace transform. Usually we shall have appropriate initial values for the function <m>y</m> and its derivatives so that there will be no undetermined constants in the solutions. The four steps are:
  <ol>
    <li>
      <p>
        <alert>Find the Laplace transform of the whole ODE.</alert> This will require using the transform of derivatives property from Theorem <xref ref="thm-trans_deriv"/> to transform the left hand side and using the table of transforms, if necessary, to transform the function <m>g</m> on the right.
      </p>
    </li>
    <li>
      <p>
        <alert>Insert the initial conditions.</alert> This should supply actual values for the undetermined constants <m>y_i</m> from the left hand side.
      </p>
    </li>
    <li>
      <p>
        <alert>Solve the resulting equation for <m>\bar{y}</m>, the Laplace transform of <m>y</m>.</alert> This step should be straightforward and just relies on regular algebraic manipulation to find a formula in the variable <m>s</m> for <m>\bar{y}</m>.
      </p>
    </li>
    <li>
      <p>
        <alert>Find the inverse transform of <m>\bar{y}</m> to get the solution <m>y(t)</m> of the original ODE.</alert> This may well require some simplifying work do be done on <m>\bar{y}</m> first, so that we have it in a form that enables us to find its inverse transform using the table.
      </p>
    </li>
  </ol>
  We illustrate these steps now with some examples.
  </p>
  <example>
  <title>Solving a second-order ODE</title>
      <statement>
      <p>
       Solve
       <me>
        \frac{d^2y}{dt^2} - 5\frac{dy}{dt} + 4y = 12,
       </me>
      subject to the intitial conditions <m>y(0)=y'(0)=0</m>.
      </p>
    </statement>
    <solution>
      <p>
        Transforming the equation gives
<me>
s^2 \bar{y} - s y_0 -y_1 - 5(s \bar{y} - y_0) + 4\bar{y} = \frac{12}{s}.
</me>
Inserting the initial values this becomes
<me>
  s^2 \bar{y} - 5s \bar{y} + 4\bar{y} = \frac{12}{s}.
</me>
Solving for <m>\bar{y}</m> gives
<me>
\bar{y} = \frac{12}{s (s^2 - 5 + 4)}.
</me>
We wish now to recover <m>y(t)</m> by taking inverse transform of <m>\bar{y}</m>. However our current expression for <m>\bar{y}</m> is not featured anywhere on the table of Laplace transforms. So we seek a simpler expression for this rational function, i.e. we find its partial fraction expansion.
<md>
  <mrow>\bar{y} \amp = \frac{12}{s (s^2 - 5s + 4)},</mrow>
  <mrow> \amp = \frac{12}{s(s-4)(s-1)}, </mrow>
  <mrow> \amp = \frac{3}{s} + \frac{1}{s-4} - \frac{4}{s-1}.</mrow>
</md>
Now we have <m>\bar{y}</m> expressed as a linear combination of functions, each of which can be found on table of Laplace transforms. So reading the inverse transforms from the table we find the solution <m>y</m> as
<me>
  y(t) = 3 + e^{4t} - 4e^t.
  </me>
      </p>
    </solution>
    </example>
  <example>
    <title>Solving a first-order ODE</title>
    <statement>
      <p>
        Solve
        <me>
          \frac{dy}{dt} + 2y = 4,
        </me>
        subject to the initial condition <m>y(0)=3</m>.
      </p>
    </statement>   
    <solution>
      <p>
        In lecture.
      </p>
    </solution>
  </example>
  <p>
    If one encounters irreducible quadratic factors in the denominator of <m>\bar{y}</m> then in the resulting partial fraction expansion they should be rewritten by <em>completing the square</em>. The inverse transforms of these terms will then contribute trigonometric or hyperbolic functions to the solution <m>y</m>.
  </p>
  <example><title>Dealing with irreducible quadratic factors</title>
      <statement>
      <p>
        Find the inverse transform of <m>\bar{y}</m>, where
<me>
\bar{y} = \frac{3s+18}{s^2 + 4s + 13} .
</me>
      </p>
    </statement>
    <solution>
      <p>
        Checking its discriminant confirms that the denominator is irreducible. We proceed according the guidance above,
        <md>
          <mrow>\bar{y}  = \frac{3s+18}{s^2 + 4s + 13} \amp= \frac{3s+18}{(s + 2)^2 + 9},</mrow>
          <mrow> \amp = 3\frac{s+2}{(s + 2)^2 + 3^2} + 4\frac{3}{(s + 2)^2 + 3^2}.</mrow>
        </md>
        We chose to make the final arrangements so that <m>\bar{y}</m> is now expressed as a linear combination of functions of <m>s</m>, both of which we can locate in the table. The inverse transform is now read off the table as
<me>
y(t) = 3 \, e^{-2t}\cos(3t) + 4 \, e^{-2t}\sin(3t).
</me>
      </p>
    </solution>
  </example>
</section>

<section xml:id="sec-simultaneous_ODEs">
  <title>Solving simultaneous (coupled) ODEs</title>
  <p>
    The Laplace transform method can also be applied to pairs of ODEs, both involving two unknown functions, <m>x</m> and <m>y</m> say, to which a simultaneous solution <m>(x,y)</m> is sought. Or indeed, we could apply it to a set of <m>n</m> ODEs featuring <m>n</m> unknown functions <m>x_1, \dots , x_n</m>, although the details would soon become unwieldy (by hand at least) as <m>n</m> increases.

    We follow the four steps given previously, only in step 3 we will require strategies like substitution and elimination to find expressions for <m>\bar{x}</m> and <m>\bar{y}</m> as functions of <m>s</m> so that inverse transforms can be taken and the solution recovered.
  </p>
  <example><title>Solving coupled ODEs</title>
      <statement>
      <p>
        Find the solution <m>(x,y)</m> that solves the pair of coupled ODEs,
        <md>
          <mrow>\frac{dx}{dt} + 4 \frac{dy}{dt} + 5x  \amp =3,</mrow>
          <mrow>\frac{dy}{dt} + 3x + y \amp =2t,</mrow>
        </md>
        subject to the initial conditions <m>y(0)=2</m> and <m>x(0)=-3</m>.
      </p>
    </statement>
    <solution>
      <p>
        In the lecture.
      </p>
    </solution>
  </example>
</section>

<section xml:id="sec-dirac_heaviside">
  <title>Impulses and steps: The Dirac and Heaviside functions</title>
  <p>
    Some applications generate differential equations featuring discontinuous function. In this section we show how such functions can be represented and dealt with by the Laplace transform solution method.
  </p>
  <figure xml:id="fig-circuit">
    <caption>Electrical circuit</caption>
    <image width="50%">
        <latex-image >
          \begin{tikzpicture}[circuit ee IEC,x=3cm,y=2cm,semithick,
          every info/.style={font=\footnotesize},
          small circuit symbols,
          set resistor graphic=var resistor IEC graphic,
          set diode graphic=var diode IEC graphic,
          set make contact graphic= var make contact IEC graphic,
          scale=0.75]
          % Let us start with some contacts:
          \foreach \contact/\x in {1/1,2/2,3/3}
          {
          \node [contact] (top contact \contact) at (\x,0) {};
          \node [contact] (bottom contact \contact) at (\x,1) {};
          }
          %\draw (top contact 1) -- (top contact 2) -- (top contact 3)
          %-- (bottom contact 3) -- (bottom contact 2) -- (bottom contact 1) -- (top contact 1);

          \draw (top contact 1) to [resistor={info=R\,}] (top contact 2);
          \draw (top contact 2) to [inductor={info=L}]  (top contact 3);
          \draw (top contact 3) to [capacitor={info=C}]  (bottom contact 3);
          \draw (bottom contact 3) to [voltage source={info'=$E_0 \sin(\omega t)$}]  (bottom contact  2);
          \draw (bottom contact 2) to [make contact]  (bottom contact  1);
          \draw (bottom contact 1) --  (top contact  1);
          \end{tikzpicture}
        </latex-image>
    </image>
</figure>
  <p>
    For example, if <m>\mathrm{i}(t)</m> is the current in the electrical circuit shown in figure <xref ref="fig-circuit"/>, then <m>\mathrm{i}(t)</m> satisfies the integral equation
<me>
L \frac{di}{dt} + Ri + \frac{1}{C} \int_0^1 i(t) \, dt = E_0 \sin(\omega t).
</me>
If the circuit is switched on for a certain time period then the graph of the current might be shown by figure <xref ref="fig-alternating"/>, or for a direct current (a battery say) powering the circuit, like that in figure <xref ref="fig-direct"/>.
  </p>
   <sidebyside widths="40% 40%" margins="auto" valign="top">
    <figure xml:id="fig-alternating">
    <caption>Alternating current</caption>
    <image width="50%">
        <latex-image >
          \begin{tikzpicture}
          \coordinate (origin) at (0,0);
          \coordinate (X) at (3,0);
          \coordinate (Y) at (0,3);

          \draw[->, color=black] (origin) node[below left] {$O$} -- (X) node[below] {Time};
          \draw[->, color=black] (origin) -- (Y) node[left] {Current};

          \coordinate (A) at (1,1);
          \coordinate (a) at (1,0);
          \coordinate (B) at (2,1);
          \coordinate (b) at (2,0);

          \draw[decorate,decoration={snake}] (A) -- (B);
          \draw[dashed] (a) -- (A);
          \draw[dashed] (b) -- (B);
          \end{tikzpicture}
        </latex-image>
    </image>
</figure>
    <figure xml:id="fig-direct">
    <caption>Direct current</caption>
    <image width="50%">
        <latex-image >
          \begin{tikzpicture}
          \coordinate (origin) at (0,0);
          \coordinate (X) at (3,0);
          \coordinate (Y) at (0,3);

          \draw[->, color=black] (origin) node[below left] {$O$} -- (X) node[below] {Time};
          \draw[->, color=black] (origin) -- (Y) node[left] {Current};

          \coordinate (A) at (1,1);
          \coordinate (a) at (1,0);
          \coordinate (B) at (2,1);
          \coordinate (b) at (2,0);

          \draw (A) -- (B);
          \draw[dashed] (a) -- (A);
          \draw[dashed] (b) -- (B);
          \end{tikzpicture}
        </latex-image>
    </image>
</figure>
</sidebyside>
<p>
  Such functions, which are <em>switched on</em> in a certain time interval, and then <em>switched off</em> at other times, can be expressed with the aid of the Heaviside step function.
</p>
<definition xml:id="def-heaviside">
<title>Heaviside step function</title>
  <statement>
    <p>
      The <em>Heaviside step function</em> <m>H(t)</m> is defined as
<me>
H(t) = \begin{cases} 0 \amp\text{if } t\lt 0 \\ 1 \amp\text{if } t \geq 0\end{cases} .
</me>
Its graph is shown in figure <xref ref="fig-heaviside"/>. We think of it as representing a signal of strength <m>1</m> which is switched off until <m>t=0</m> and then switched on thereafter.
    </p>
  </statement>
</definition>
<figure xml:id="fig-heaviside">
    <caption>The Heaviside step function</caption>
    <image width="40%">
        <latex-image >
          \begin{tikzpicture}[]
          \coordinate (origin) at (0,0);
          \coordinate (X) at (3,0);
          \coordinate (Y) at (0,3);


          \draw[->, color=gray] (origin) node[below left] {$O$} -- (X) node[below] {$t$};
          \draw[->, color=gray] (origin) -- (Y) node[left] {$H(t)$};


          \draw[->] (0,1) node[left] {$1$} -- (3,1);
          \draw (-1,0) -- (origin);

          \end{tikzpicture}
        </latex-image>
    </image>
</figure>
<p>
  One can easily have the signal switch on at other points apart from <m>t=0</m>, by considering the Heaviside function where the argument is shifted by a fixed amount. Consider the function <m>H(t-a)</m> which satisfies
<me>
H(t-a) = \begin{cases} 0 \amp \text{if } t\lt a \\ 1 \amp \text{if } t \geq a\end{cases} ,
</me>
and whose graph is shown in figure <xref ref="fig-heaviside_at_a"/>.
</p>
<figure xml:id="fig-heaviside_at_a">
    <caption>The Heaviside step function <m>H(t-a)</m></caption>
    <image width="40%">
        <latex-image >
          \begin{tikzpicture}[scale=0.75]
          \coordinate (origin) at (0,0);
          \coordinate (X) at (3,0);
          \coordinate (Y) at (0,3);

          \draw[->, color=gray] (-1,0) -- (origin) node[below left] {$O$} -- (X) node[below] {$t$};
          \draw[->, color=gray] (origin) -- (Y) node[left] {$H(t-a)$};


          \draw (0,1) node[left] {$1$};
          \draw[->] (1,1) -- (3,1);
          \draw[dashed] (1,0) node[below] {$a$} -- (1,1);

          \end{tikzpicture}
        </latex-image>
    </image>
</figure>
<p>
        Using combinations of different Heaviside functions like this we can produce arbitrary signals that are switched on in a desired time interval and switched off at other times, as in the following examples. 
</p>
<example><title>Applications of the Heaviside step function</title>
  <statement>
    <p>
      <ol>
        <li>
          <p>
            Let <m>a \lt b</m>. What are the various values taken on by the function <m>g</m> defined by
            <me>
            g(t) = H(t-a) - H(t-b).
            </me>
            Draw the graph of <m>g</m>.
          </p>
        </li>
        <li>
          <p>
           Let <m>a \lt b</m>. What are the various values taken on by the function <m>f</m> defined by
            <me>
            f(t) = \big ( 1 + \cos(t) \big ) \big ( H(t-a) - H(t-b) \big ).
            </me>
            Draw the graph of <m>f</m>. 
          </p>
        </li>
        <li>
          <p>
            Consider the function <m>V</m> defined by
            <me>
            V(t) = \begin{cases} 0 \amp \text{if } t \lt 0 \\ 
            t \amp\text{if } 0 \leq t \lt 2 \\ 
            2 \amp \text{if } t \geq 2 \end{cases}.
            </me>
            Draw a graph of <m>V</m> and find a definition for <m>V</m> (not utilising different cases) involving suitable Heaviside step functions.
          </p>
        </li>
      </ol>
    </p>
  </statement>
  <solution>
    <p>
      In lecture.
    </p>
  </solution>
</example>
<p>
  Its important to remember that a function <m>\phi(t) \big ( H(t-a) - H(t-b) \big )</m> is the signal <m>\phi(t)</m> switched on between the values <m>t=a</m> and <m>t=b</m> and switched off at other times.
</p>
<p>
  We also want the ability to model <em>impulses</em>, which is done with the Dirac delta function.
</p>
<definition xml:id="def-dirac"><title>Dirac delta function</title>
 <statement>
    <p>
      The <em>Dirac delta</em> function <m>\delta</m> is the function<fn>Strictly speaking this is not a real valued function in the usual sense, it is more properly called a <em>distribution</em></fn> defined by
      <me>
      \delta(t) = \begin{cases} \infty \amp\text{if } t=0 \\ 
      0 \amp\text{if } t \neq 0 \end{cases}.
      </me>
      The position of the <em>spike</em> can be moved, just as we moved the step in the Heaviside function earlier, by shifting the argument, i.e. the function <m>\delta(t-a)</m> satisfies
      <me>
      \delta(t-a) = \begin{cases} \infty \amp\text{if } t=a \\ 
      0 \amp\text{if } t \neq a\end{cases}.
      </me>
    </p>
  </statement>
</definition>
<p>
  The transforms of the functions $\delta$ and $H$ are given by the following results.
</p>
<theorem xml:id="thm-transform_heaviside"><title>Transform of the Heaviside</title>
  <statement>
    <p>
      The Laplace transform of the Heaviside step function <m>H(t-a)</m> is given by
      <me>
      \L{H(t-a)} = \frac{e^{-as}}{s} .
      </me>
    </p>
  </statement>
  <proof>
    <p>
      In lecture.
    </p>
  </proof>
</theorem>
<theorem xml:id="thm-transform_heaviside_product">
<title>Transform of products with Heaviside</title>
  <statement>
    <p>
      If <me>\L{f(t)} = F(s)</me> then the Laplace transform of the function <m>f(t-a)H(t-a)</m> is given by
      <me>
      \L{f(t-a)H(t-a)}= e^{-as} F(s) .
      </me>
    </p>
  </statement>
  <proof>
    <p>
      In lecture. 
    </p>
  </proof>
</theorem>
<theorem xml:id="thm-transform_dirac">
<title>Transform of the Dirac delta function</title>
  <statement>
    <p>
      The Laplace transform of the Dirac delta function <m>\delta(t-a)</m> is given by
      <me>
      \L{\delta(t-a)} = e^{-as} .
      </me>
    </p>
  </statement>
  <proof>
    <p>
      In lecture.
    </p>
  </proof>
</theorem>
<p>
  These results can be applied to find transforms and inverse transforms of more general functions involving <m>H</m> and <m>\delta</m>.
</p>
<example>
<title>Working with <m>H</m> and <m>\delta</m></title>
  <statement>
    <p>
      <ol>
        <li>
          <p>
            Find the Laplace transform of the function <m>R</m> defined by
            <me>
            R(t) = t^2 H(t-2).
            </me>
            Hint: For this it is necessary to re-express <m>R</m> as a combination of functions, all of which have the form <m>f(t-a)H(t-a)</m>, so that we can apply theorem <xref ref="thm-transform_heaviside_product"/>.
          </p>
        </li>
        <li>
          <p>
            Find the inverse Laplace transform of the function <m>U</m> defined by
            <me>
            U(s) = e^{-3s} + \frac{e^{-3s}}{s^2 + 1}.
            </me>
          </p>
        </li>
      </ol>
    </p>
  </statement>
  <solution>
    <p>
      In lecture.
    </p>
  </solution>
</example>
<p>
  With the help of the results and techniques concerning <m>\delta</m> and <m>H</m> which we have described above we should now be able to solve a wider class of ODEs, i.e. those involving these functions. We still follow the basic four steps as described before.
</p>
<example>
<title>ODE featuring a Heaviside step function</title>
  <statement>
    <p>
      Solve the ODE
      <me>
      \frac{d^2 y}{dt^2} - 4 \frac{dy}{dt} + 3y = 6 H(t-5),
      </me>
    subject to the initial conditions <m>y(0)=y'(0)=0</m>.
    </p>
  </statement>
  <solution>
    <p>
      In lecture.
    </p>
  </solution>
</example>
</section>

<section xml:id="sec-final">
  <title>Further terminology and results</title>
  <p>
    In the solution of the ODE
<me>
  \frac{d^2 y}{dt^2} + 4y = 10 e^{-t} + 8,
</me>
subject to <m>y(0)=7</m> and <m>y'(0)=-2</m> we get
<me>
y(t) = 3 \cos(2t) + 2 e^{-t} + 2.
</me>
As <m>t \to \infty</m> the first and last term of <m>y</m> will continue to have an effect on <m>y</m>, however the middle exponential term decays (converges) to <m>0</m>. We call such terms in a solution that converge to 0 as <m>t \to \infty</m>, <alert>transient</alert> terms. The other terms, which do not decay, are called <alert>steady state</alert> terms.
  </p>
  <p>
    If <m>F(s)</m> is the Laplace transform of <m>f(t)</m> then there are various relationships between the limits of these functions (assuming the limits exist). Generally we have
    <me>
      \lim_{s \to \infty} F(s)=0.
    </me>
  </p>
  <theorem xml:id="thm-initial_value">
  <title>Initial value theorem</title>
      <statement>
      <p>
      <me>
      \lim_{t \to \infty} f(t) = \lim_{s \to 0} sF(s).
      </me>
      </p>
    </statement>
    <proof>
      <p>
        Omitted.
      </p>
    </proof>
  </theorem>
  <theorem xml:id="thm-final_value">
  <title>Final value theorem</title>
      <statement>
      <p>
        <me>
          \lim_{t \to 0} f(t) = \lim_{s \to \infty} sF(s).
        </me>
        
      </p>
    </statement>
    <proof>
      <p>
        Omitted.
      </p>
    </proof>
  </theorem>
  
  







</section>

<!-- <xi:include href="./integrals01.ptx" /> -->

 </chapter>
